# üìñ LLM_related_paper_and_github

## Survey or consluion
- [Augmented Language Models: a Survey](https://arxiv.org/abs/2302.07842) (Feb 2023) [code]
- [Towards Reasoning in Large Language Models: A Survey.]() 
- [Reasoning with Language Model Prompting: A Survey]()
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223) (April 2023)
- [Tool Learning with Foundation Models](https://arxiv.org/abs/2304.08354) (June 2023)

## Foundation Models

- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://scontent-sin6-2.xx.fbcdn.net/v/t39.2365-6/10000000_662098952474184_2584067087619170692_n.pdf?_nc_cat=105&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=qhK-ahCbkBMAX9Dzaw7&_nc_ht=scontent-sin6-2.xx&oh=00_AfCAxDCJgixsboS6n2Wjww-x9hIayo0iASA47IddwbgnJw&oe=64BE66FF)
- [GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://arxiv.org/abs/2103.10360)
- [GLM-130B: An Open Bilingual Pre-trained Model](https://arxiv.org/abs/2210.02414)

## Chain-of-thoughts

- [Reflexion: an autonomous agent with dynamic memory and self-reflection]()
- [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://arxiv.org/abs/2305.04091v3) (May 2023)
- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
- [[self-COT]Self-consistency improves chain of thought reasoning in language models](https://arxiv.org/abs/2203.11171) [code]()
- [Universality and Limitations of Prompt Tuning](https://arxiv.org/abs/2305.18787) (May 2023)
- [Self-Critique Prompting with Large Language Models for Inductive Instructions](https://arxiv.org/abs/2305.13733) (May 2023, Ëá™ÊàëÊâπËØÑ)
- [Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs](https://arxiv.org/abs/2305.11860) (May 2023)
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) (May 2023)
- [Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models](https://arxiv.org/abs/2305.10276) (May 2023)  
- [Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling](https://arxiv.org/abs/2305.09993) (May 2023) [ÈááÊ†∑ÁÆóÊ≥ïÊõ¥Êñ∞]
- [Boosted Prompt Ensembles for Large Language Models](https://arxiv.org/abs/2304.05970) (April 2023)
- [REFINER: Reasoning Feedback on Intermediate Representations](https://arxiv.org/abs/2304.01904) (April 2023)
- [Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/abs/2303.17651v1) (Mar 2023)
- [Fairness-guided Few-shot Prompting for Large Language Models](https://arxiv.org/abs/2303.13217) (Mar 2023)
- [Tab-CoT: Zero-shot Tabular Chain of Thought](https://arxiv.org/abs/2305.17812) (May 2023)
- [Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance](https://arxiv.org/abs/2305.17306) (May 2023)
- [SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks](https://arxiv.org/abs/2305.17390v1) (May 2023) [Âø´ÊÖ¢ÊÄùÁª¥]
- [Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings](https://arxiv.org/abs/2305.02317v1) (May 2023)
- [Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction](https://arxiv.org/abs/2305.02466v1) (May 2023)
- [The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning](https://arxiv.org/abs/2305.14045) (May 2023)
- [Active Learning Principles for In-Context Learning with Large Language Models](https://arxiv.org/abs/2305.14264) (May 2023)
- [Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs](https://arxiv.org/abs/2305.14279) (May 2023)
- [Improving Factuality and Reasoning in Language Models through Multiagent Debate](https://arxiv.org/abs/2305.14325) (May 2023)
- [ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on\\ Chat-based Large Language Models](https://arxiv.org/abs/2305.14323) (May 2023)

## Prompt
- [awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts)
- [awesome-chatgpt-prompts-zh](https://github.com/PlexPt/awesome-chatgpt-prompts-zh)
  
## Finetune
### base
- [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention]()
- [LoRA: Low-Rank Adaptation of Large Language Models]()
- [SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL]()
- [Focused Prefix Tuning for Controllable Text Generation](https://arxiv.org/abs/2306.00369) (June 2023)

### model
- [Github ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B)
- [Github ChatRWKV](https://github.com/BlinkDL/ChatRWKV)
- [Github ChatLaw(‰∏≠ÊñáÊ≥ïÂæãÂ§ßÊ®°Âûã)](https://github.com/PKU-YuanGroup/ChatLaw)
- [Github Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese)

### multimodal

## ‚ú® some principle

- [Meta-in-context learning in large language models](https://arxiv.org/abs/2305.12907) (May 2023)
- [Post Hoc Explanations of Language Models Can Improve Language Models](https://arxiv.org/abs/2305.11426) (May 2023)  
- [What In-Context Learning "Learns" In-Context: Disentangling Task Recognition and Task Learning](https://arxiv.org/abs/2305.09731) (May 2023)
- [Heterogeneous Value Evaluation for Large Language Models](https://arxiv.org/abs/2305.17147) (May 2023)
- [Large Language Models as Tool Makers](https://arxiv.org/abs/2305.17126v1) (May 2023)
- [NPPrompt: Pre-trained Language Models Can be Fully Zero-Shot Learners](https://arxiv.org/abs/2212.06950) (Zero-Shot)

## Agent
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761) [code]
- [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models](https://arxiv.org/abs/2303.04671) [code]
- [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580) [code]
- [Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow](https://arxiv.org/abs/2306.07209) (June 2023ÔºåÊï∞ÊçÆÂàÜÊûêagent)
- [Voyager: An Open-Ended Embodied Agent with Large Language Models](https://arxiv.org/abs/2305.16291) ÔºàMay 2023ÔºåÊ∏∏ÊàèagentÔºâ
- [CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge](https://arxiv.org/abs/2305.09955) (May 2023)
- [Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents](https://arxiv.org/abs/2306.03314)
- [FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance](https://arxiv.org/abs/2305.05176v1) (May 2023)[ÊàêÊú¨‰∏éÊÄßËÉΩ]
- AgentGPT [code](https://github.com/reworkd/AgentGPT)
- AutoGPT [[code](https://github.com/Significant-Gravitas/Auto-GPT)]

### agent‰∫§‰∫í
- [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442) (Apr 2023)
- [CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society](https://arxiv.org/abs/2303.17760) (Mar 2023)


## Application
- [ChatPaper](https://github.com/kaixindelele/ChatPaper)
- [ChatPaper](https://github.com/kaixindelele/ChatPaper)
- [document: langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM)
- [ChatALL: multi-llm](https://github.com/sunner/ChatALL)
- [ÂæÆ‰ø°‰∏™‰∫∫Âè∑Êé•Âè£„ÄÅÂæÆ‰ø°Êú∫Âô®‰∫∫ÂèäÂëΩ‰ª§Ë°åÂæÆ‰ø°Ôºå‰∏âÂçÅË°åÂç≥ÂèØËá™ÂÆö‰πâ‰∏™‰∫∫Âè∑Êú∫Âô®‰∫∫](https://github.com/littlecodersh/ItChat)
- [wechat-chatgpt](https://github.com/fuergaosi233/wechat-chatgpt)
- [chatgpt-on-wechat](https://github.com/zhayujie/chatgpt-on-wechat)
- [ChatGPT-Midjourney](https://github.com/Licoy/ChatGPT-Midjourney)
- [chatÈõÜÊàêÂà∞ÊµèËßàÂô®-chatGPTBox](https://github.com/josStorer/chatGPTBox)
- [Chat2DB](https://github.com/chat2db/Chat2DB)


### code
#### SQL
- [SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL](https://arxiv.org/abs/2306.00739) (June 2023)
- [Exploring Chain-of-Thought Style Prompting for Text-to-SQL](https://arxiv.org/abs/2305.14215) (May 2023)


### writing
- ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing


### document
- [PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents](https://arxiv.org/abs/2305.14564v1) (May 2023)
- [Github gpt4-pdf-chatbot-langchain](https://github.com/mayooear/gpt4-pdf-chatbot-langchain)

### reason
- [Interpretable Math Word Problem Solution Generation Via Step-by-step Planning](https://arxiv.org/abs/2306.00784) (June 2023)
- [Let's Verify Step by Step](https://arxiv.org/abs/2305.20050) (May 2023)
- [Reasoning with Language Model is Planning with World Model](https://arxiv.org/abs/2305.14992v1) (May 2023)
- [Why think step-by-step? Reasoning emerges from the locality of experience](https://arxiv.org/abs/2304.03843) (April 2023)
- [MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning](https://arxiv.org/abs/2205.00445) (May 2023)


### struct-data
- StructGPT: A General Framework for Large Language Model to Reason over Structured Data
- DiffuD2T: Empowering Data-to-Text Generation with Diffusion(ÁúãËµ∑Êù•ÊòØË°®Ê†ºÊï∞ÊçÆ)
- [PRODIGY: Enabling In-context Learning Over Graphs](https://arxiv.org/abs/2305.12600v1) (May 2023)

### classification
- [TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks](https://arxiv.org/abs/2305.11430) (May 2023)  
- [PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training](https://arxiv.org/abs/2305.13723) (May 2023)
- [Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation](https://arxiv.org/abs/2305.13785) (May 2023)

  
